{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdf2de0",
   "metadata": {},
   "source": [
    "**If training on colab, be sure to use a GPU (runtime > Change runtime type > GPU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3483926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run the lines below if running in google colab\n",
    "# !pip install tensorflow==2.4.3\n",
    "# !git clone https://github.com/jlaihong/image-super-resolution.git\n",
    "# !mv image-super-resolution/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77835c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b18a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.test.is_built_with_cuda()\n",
    "print(tf.version.VERSION)\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab2bcb",
   "metadata": {},
   "source": [
    "# SRResNet and SRGAN Training for Image Super Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1597e6",
   "metadata": {},
   "source": [
    "An Implementation of SRGAN: https://arxiv.org/pdf/1609.04802.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fc6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, MeanAbsoluteError\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from PIL import Image\n",
    "\n",
    "from datasets.div2k.parameters import Div2kParameters \n",
    "from datasets.div2k.loader import create_training_and_validation_datasets\n",
    "from utils.dataset_mappings import random_crop, random_flip, random_rotate, random_lr_jpeg_noise\n",
    "from utils.metrics import psnr_metric\n",
    "from utils.config import config\n",
    "from utils.callbacks import SaveCustomCheckpoint\n",
    "from models.srresnet import build_srresnet\n",
    "from models.srgan import build_discriminator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1761209",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9272c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_key = \"realistic_difficult_x4\"\n",
    "\n",
    "data_path = config.get(\"data_path\", \"\") \n",
    "\n",
    "div2k_folder = os.path.abspath(os.path.join(data_path, \"div2k\"))\n",
    "\n",
    "dataset_parameters = Div2kParameters(dataset_key, save_data_directory=div2k_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639c8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_crop_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d48fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mappings = [\n",
    "    lambda lr, hr: random_crop(lr, hr, hr_crop_size=hr_crop_size, scale=dataset_parameters.scale), \n",
    "    random_flip, \n",
    "    random_rotate, \n",
    "    random_lr_jpeg_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850ab510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = create_training_and_validation_datasets(dataset_parameters, train_mappings)\n",
    "\n",
    "valid_dataset_subset = valid_dataset.take(10) # only taking 10 examples here to speed up evaluations during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b92c5",
   "metadata": {},
   "source": [
    "## Train the SRResNet generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8149e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_srresnet(scale=dataset_parameters.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58b5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(\"weights\\srresnet_realistic_difficult_x4\\generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7616b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir=f'./ckpt/sr_resnet_{dataset_key}'\n",
    "\n",
    "learning_rate=1e-4\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                 epoch=tf.Variable(0),\n",
    "                                 psnr=tf.Variable(0.0),\n",
    "                                 optimizer=Adam(learning_rate),\n",
    "                                 model=generator)\n",
    "\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                directory=checkpoint_dir,\n",
    "                                                max_to_keep=3)\n",
    "\n",
    "if checkpoint_manager.latest_checkpoint:\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {checkpoint.step.numpy()} with validation PSNR {checkpoint.psnr.numpy()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab25138e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing Training from epoch 0. Remaining epochs: 1.\n",
      "44333/44333 [==============================] - ETA: 0s - loss: 844.6963 - psnr_metric: 22.5925     - ETA: 2:08:41 - loss: 851.3547 - psnr_metric: - ETA: 2:08:44 - los - ETA: 2:08:43 - loss: 850.9679 - psnr_met - ETA: 2:08:46 - loss: 850.5 - ETA: 2:08:48 - loss: 851.0089 - psnr_metric: 22. - ETA: 2:08:48 - loss: 850.8787 - ETA: 2:08:50 - loss: 850.1516 - psnr_metri - ETA: 2:08:52 - loss - - ETA: 2:08:56 - lo - ETA: 2:08:56 - loss: 851.8068 - psnr_metric: 22 - ETA: 2:08:47 - loss: 851. - ETA: 2:07:41 - loss: 85 - ETA: 2:07:37 - loss: 852.0264 - psnr_metric: 22 - ETA: 2:07:37  - ETA: 2:07:33 - loss: 851.7189 - psnr_ - ETA: 2:07:30 - loss: 851.5706 - psnr - ETA: 2:07:29 - loss: 851.6475 - psnr_metric: 22. - ETA: 2:07:28 - loss: 851.5891 - psnr_metric:  - ETA: 2:07:27 - los - ETA: 2:07:14 - loss: 850.5547 - psnr_me - ETA: 2:07:13 - loss: 850.8912 - psnr_metric: 22.57 - ETA: 2:07:13 -  - ETA: 2:07:07 - loss:  - ETA: 2:07:02  - ETA: 2:06:26 - loss: 849. - ETA: 2:06:16 - loss: 850 - ETA: 2:06:11 - loss: 850.6731 - psnr_metr - ETA: 2:06:00 - loss: 850.8674 - - ETA: 2:05:56 - loss: 851.0296 - psnr_metri - ETA: 2:05:55 - loss: - ETA: 2:05:49 - loss: 850.8506 - psnr_metric: 22.56 - ETA: 2:05:49 - loss: 850.8610 - psnr_metric: - ETA: 2:05: - ETA: 2:05:40 - loss: 850.7 - ETA: 2:05:36 - loss: 850.91 - ETA: 2:05:3 - ETA: 2:05:27 - loss: 850.3496 - psnr_metric: 22 - ETA: 2:05:27 - loss: 850.0081 - psnr_ - ETA: 2:05:24 - loss: 850.1948 - psnr_metric: 22.564 - ETA: 2:05:24 - loss: 850.2126 - psnr_metric: 22.56 - ETA: 2:05:24 - loss: 850.2742 - psnr_ - - ETA: 2:05:13 - loss: 850.4767 - ETA: 2:05:09 - loss: 850.4253 -  - ETA - ETA: 2:04:19 - loss: 849.8686 - psnr_metric:  - ETA: 2:04:17 - loss: 849.9487 - psnr_metric: 2 -  - ETA: 2:04:08 - loss: 849.4149 -  - ETA: 2:04:05 - loss: 8 - ETA: 2:03:33 - loss: 849.8344 - ETA: 2:02:15 - loss: 847.4982 - psn - ETA: 2:02:13 - loss: 847.4858 - psnr_metric: 2 - ETA: 2:02:03 - loss: 848.4315 - psnr_metric: 22.5 - ETA: 2:02:02 - loss: - ETA: 2:01 - ETA: 2:01:40 - loss: 847.7598 - ETA: 2:01:18 - loss: 847.7794 - psn - ETA: 2:01:15 - loss: 847.7756 - psnr_ - ETA: 2:01:13 - loss: 847.5362 - psnr_m - ETA: 2:01:10 - loss: 847.2889 - psnr_metric - ETA: 2:01:09 - los - ETA: 2:01:02 - loss: 847.8857 -  - ETA: 2:00:21 - loss: 847.8161 - psnr_metric: 22.57 - ETA: 2:00:20 - loss: 847.879 - ETA: 2:00:17 - loss: 847.6545 - psnr_metric - ETA: 2:00:15 - loss: - ETA: 1:58:59 - loss: 847.5638 - psnr_metric: 2 - ETA: 1:5 - ETA: 1:57:34 - lo - ETA: 1:57:29 - loss: 84 - ETA: 1:57:24 - loss: 846.2949 - psnr_metric:  - ETA: 1:57:23 - loss: 846.0861 - psnr_metric: 22. - ETA: 1:57:22 - loss: 8 - ETA: 1:57:17 - loss: 845.9059 - psnr_metric - ETA: 1:57:16 - loss: 846.1190 -  - ETA: 1:57:12 - loss: 845.6373 - - ETA: 1:57:08 - loss: 845.6743 -  - ETA: 1:57:05 - los - ETA: 1:56:59 - loss: 845.6796 - psnr_m - ETA: 1:56:57 - loss: 845.7083 - psnr_met - ETA: 1:56:55 - loss: 845.6290 - psnr_metric: 22. - ETA: 1:56:54 - loss: 845.7504 - ps - ETA: 1:56:51 - loss:  - ETA: 1:56:46 - loss: 845.76 - ETA: 1:56:41 - loss: 845.7890 - psnr_metri - ETA: 1:56:10 - loss: 844.8566 - psnr_metric - - ETA: 1: - ETA: 1:55:51 - loss - ETA: 1:55:45 - loss: 845.1216 - psnr_metric: 22.5 - ETA: 1:55:45 - loss - ETA: 1:55:39 - loss: 845.1508 - psnr_metric: 22 - ETA: 1:55:38 - loss: 845.1818 - psnr_metric: - ETA: 1:55:37 - loss: 845 - ETA: 1 - ETA: 1:55:23 - loss: 844.9335 - psn - ETA: 1:54:21 -  - ETA: 1:54:15 - loss: 845.9427 - psnr_ - ETA: 1:54:12 - loss: 84 - ETA: 1:53:37 - loss: 845.3800 - psnr_m - ETA: 1:53:34 - loss: 845.3502 - psnr_metric: 2 - ETA: 1:53:33 - lo - ETA: 1:53:07 - loss: 845.0283 - psnr_m - ETA: 1:53:05 - loss: 844.8945 - psnr_metric: 22. - ETA: 1:53:05 - loss:  - ETA: 1:52:59 - loss: 84 - ETA: 1:52:33 - loss: 845.1688 - psnr_metric: 22.58 - ETA: 1:52:33 - loss: 845.2661 - ETA: 1:52:29 - loss: 845.3755 - psnr_met - ETA: 1:52:27 - loss: 845.498 - ETA: 1:52:23 - loss: 845.7393 - p - ETA: 1:52:19 - loss: 845.7999 - psnr_metric: 22.5 - ETA: 1:52:19 - l - ETA: 1:52:12 - loss: 845.8925 -  - ETA: 1:51:2 - ETA: - ETA: 1:50:02 - loss: 8 - ETA: 1:49:57 - loss: 845. - ETA: 1:49:51 - loss: 845.2626 - psnr_metric:  - ETA: 1:49:50 - loss: 845.3096 - ps - E - ETA: 1:49:17 - loss: 845.5743 - psnr_metric: 22.57 - ETA: 1:49:17 - loss: 845.591 - ETA: 1:49:02  - ETA: 1:48:45 - loss: 844.9611 - psnr_metric: 22.5 - ETA: 1:48:44 - loss: 844.9401 - psnr_met - ETA: 1:48:42 - loss: 844.8539 - psnr_metri - ETA: 1:48:41 - loss: 844.7732 - psnr_metr - ETA: 1:48:19 - loss: 844.7549 - psnr_metric:  - E - - ETA: 1:47:27 - loss: 845.3178 - psnr_metric:  - ETA: 1:47:26 - loss: 845.2956 - psnr_metric: 22. - ETA: 1:47:26 - loss: 845.2830 - psnr_metric: 22.575  - ETA - ETA: 1:45:57 - loss: 844.7131 - psnr_metri - ETA: 1:45:55 - loss: 844.6 - ETA: 1:45:50 - loss: 844. - ETA: 1:45:45 - lo - ETA: 1:45:21 - ETA: 1:45:17 - loss: 844.9956 - ps - ETA: 1:44:59 - loss: 844.988 - ETA: 1:44:56 - loss: 845.0390 - psnr_metric: 22.58 - ETA: 1:44:55 - loss: 845.0004 - psnr_metric - ETA: 1:44:54 - loss: 844.9825 - psnr_metric: 2 - ETA: 1:44:53 - loss: 844.9210 - ETA: 1:44:50 - ETA: 1:44:43 - loss: 845.1591 - psnr_metric - ETA: 1:44:41 - loss - ETA: 1:44:35 - loss: 845.3782 - psnr_ - ETA: 1:44:32 - loss: 845.5086 - psnr_ - ETA - ETA: 1:44:10 - loss: 845.2725 - psnr_metric  - ETA: 1:43: - ETA: 1:43:51 -  - ETA: 1:43:4 - ETA: 1:43:26 - loss: 845.6664 - psnr_metric: 22. - ETA: 1:43:25 - loss:  - ETA: 1:43:19 - loss: 845.8608 - psnr - ETA: 1:43:06 - loss: 845.83 - ETA: 1:42:51 - loss:  - ETA: 1:42:16 - l - ETA: 1:42:09 - loss: 846.1088 - ETA: 1:42:05 - loss: - ETA: 1:41:59 - loss: 846.0359 - psnr_met - ETA: 1:40:35 - loss:  - ETA: 1:40:30 - loss: 846.0125 - psnr - ETA - ETA: 1:39:57 - loss: 845.9956 - psnr_metric: 22.5 - ETA: 1:39:56 - loss: 845.99 - ETA: 1:39:52 - loss: 846.1657 - p - ETA - ETA: - ETA: 1 - ETA: 1:39:02 - loss: 845.566 - ETA: 1:38:47 - loss: 845.6340 - psnr_metric: 22.573 - ETA: 1: - ET - ETA: 1:37:39 - loss: 845. - ETA: 1:37: - ETA: 1:37:2 - ETA: 1:37:19 - loss: 845.724 - ETA: 1:37:14 - loss - ETA: 1:37:08 - loss: 845.7497 - psnr_metric:  - ETA: 1:37:07 - loss: 845.7004 - psn - ETA: 1:37:03 - loss: 845.76 - ETA: 1:36:38 - - ETA: 1:36:00 - loss: 845.8832  - ETA: 1:35:56 - loss:  - ETA: 1:34:48 - loss: 845.9406 -  - ETA: 1:34:44 - loss: 846.0556  - ETA: 1:34:40 - loss: 846.0164 -  - ETA: 1:3 - ETA: 1:34:29 - los - ETA: 1:34:12 - loss: 846.2682 - psnr_metric: 22.573 - ETA: 1:34:12 - loss: 846.2426 - psnr_metri - ETA: 1:34:10 - loss: 846.2449 - psnr_m - ETA: 1: - ETA: 1:33:59 - loss: 846.1953 - psnr_metric:  - ETA: 1:33:58 - loss: 8 - ETA: 1:33:52 - lo - ETA: 1:33:35 - loss: 846 - ETA: 1:33:30 - loss: 8 - ETA: 1:33:25 - loss: 846.4786 - psnr_met - ETA: 1:33:12 - loss:  - ETA: 1:33:06 - lo - ETA: 1:32:50 - loss: 846.0421 -  - ETA: 1:32:46 - loss: 846.1556 - psnr_metr - ETA: 1:28:28 - ETA: 1:28:11 - loss: 846.9304 - psnr_m - ETA: 1:28:08 - loss: 846.9106 - psnr_metric: 22. - ETA: 1:28:08 - loss: 846.8563 - psnr_metric: 22.5 - ETA: 1:27:47 - ETA:  - ETA: 1:27:10 - loss: 846.9828 - ETA: 1:26:35 - loss: 846.955 - ETA: 1:26:30 - loss: 846.8651 - psnr_ - ETA: 1:26:28 - loss: 846.9504 - psnr_m - ETA: 1:26:25 - loss: 846.9716 - psnr_metric  - ETA: 1:26:13 - loss: 847.0951 - psnr_m - ETA: 1:26:11 - - ETA: 1:26:04 - loss: 847.1331 - ps - ETA:  - ETA: 1:25:51 - loss: 847.1052 - psnr - ETA: 1:25:48 - loss: 847.1981 - psnr_metr - ETA: 1:25:36 - loss: 847.0074 -  - ETA: 1:25:32 - los - ETA: - ETA: 1:23:46 - loss: 847.073 - ETA: 1:23:42 - loss: 847.0953 - psnr_m - ETA: 1: - ETA: - ETA: 1:23:12 - loss: 847.1624 - ETA: 1:23:07 - loss: 847.1475 - psnr_metri - ETA: 1:23:05 - loss: 847.1219 - psnr_me - ETA: 1:23:03 - loss: 847.0814 - psnr_metric: 22.57 - ETA: 1:23:03  - ETA: 1:22:55 - loss: 847.0867 - psnr_metric: 22.5 - ETA: 1:22:55 - loss: 847.0871  - ETA: 1:22:5 - ETA: 1:22:43 - loss: 847.3152 - psnr_metric: 22 -  - ETA: 1:22:33 - loss: 847.1720 - - ETA: 1:22:29  - ETA: 1:22:22 - loss: 847.1365 - psnr_metric: 22.5 -  - ETA: 1:22:12 - ETA: 1 - ETA: 1:21:15 - loss:  - ETA: 1:21:10 - loss: 847.0828 - ps - ETA: 1:21:06 - loss: 847.0645 - psnr_metric: 22.573 - ETA: 1:21:06 - loss: 847.0630 - psnr_me - ETA: 1:21:04 - lo - ETA: 1:20:27 - loss: 846.9925 - psnr_ - ETA: 1:20:2 - ETA: 1:20 - ETA: 1:19:58 - loss: 847.0431 - psnr_metr - ETA: 1:19:56 - loss: 847.0255 - psnr_metric  -  - ETA: 1:18:34 - ETA: 1:18:26 - loss: 847.2891 - psnr_metric: 22.574 - ETA: 1:18:26 - loss: 847.2950 - p - ETA: 1: - ETA: 1:18:04 - loss: 847.4823 - ps - ETA: 1:18:01 - loss: 847.4 - ETA: 1:17:56 -  - ETA: 1:17 - ETA: 1:16:50 - loss: 847.3416 - ET - ETA: 1:16:2 - ETA: 1:15:59 - loss: 847.2283  - ETA: 1:15 - ETA: 1:15:47 - loss: 847.1309 - psnr_metric: 22.57 -  - ETA: 1:13:27 - loss: 847.0030 - - ETA: 1:13:23 - loss: 846.8936 - psnr_metric: 22.57 - ETA: 1:13:23 - loss: 846.915 - ETA: 1:13:19 - loss: 846.8922 - psnr_metric:  - ETA: - ETA: 1:13:08 - loss: 847.0623 - psnr_ -  - ETA: 1:12:56 - loss: 846.9272 - psnr_metric - ETA: 1:1 - ETA: 1:12:46 - -  - ETA: 1:12:19 - loss: 846.7890 - psnr_metric: 22.57 - ETA: 1:12:19 - loss: 846.7845 - psnr_metric:  - ETA: 1:12:18 - loss: 846.8030  - ETA: 1:12:14 - loss: 846.8242 - psnr_metric - ETA: 1:12:12 - loss: 846.8289 - p - ETA: 1:12:08 - loss: 846.8571 - psnr_metric - ETA: 1:12 - ETA: 1:11:59 - loss: 846.8351 - psnr_metric: 22.57 - ETA: 1:11:58 - loss: 846.8204 - psnr_metric: 22 - ETA: 1:11:58 - loss: 846. - ETA: 1:11:52 - loss: 846.7857 - p - E - ETA: 1:11:09 - los - E - ETA: 1:10:23 - loss: 846.8832 - psnr_metri - ETA: 1:10:21 - loss: 846.8979 - psnr_ - ETA: 1:10:18 - loss: 847.0298 - psnr_metric: 2 - ETA: 1:10:17 - loss: 847.0896 - psnr_ - ETA: 1:10:1 - ETA: - ETA: 1:09:58 - loss: 847.2293 - psnr_m - ETA: 1:09: - ETA: 1:09:48 - loss: 847. - ETA: 1: - ETA: 1:09:04 - loss: 847.0818 - psnr_metric: 22.5 - ETA: 1:09:04 - loss: 847.0752 - psnr_metric: 22.57 - ETA: 1:09:03 - loss: 847.0681 - psnr_me - ETA: 1:08:40 - loss:  - ETA: 1:08:35 - lo - ETA: 1:08:28 - loss: 846.8865 - psnr_metric: 22.578 - ETA: 1:08:28 - loss: 846.8840 - psnr_metric: 22.5 - ETA: 1:08:28 - loss: 8 - ETA: 1:08:22 - loss: 846.7880 - psnr_metric: 2 - ETA: 1:08:21 - loss: 846.7466 - psn - ETA: 1:08:18 - loss: 846.7822 - psnr_metric: 22.57 - ETA: 1:08:18 - los - ETA: 1:08:01 - loss: 8 - - ETA: 1:07:46 - loss: 846.9620 -  - ETA: 1:07:22 - loss: 847.1423 - psnr_me - ETA: 1 - ETA: 1: - ET - ETA: 1:06:03 - loss: 846.8344  - ETA: 1:05:59 - loss: 846 - ETA: 1:05:54 - loss: 846 - ETA: 1:05:49 - loss: 8 - ETA: 1:05:33 - loss: 846.7350 - psnr_met - ETA: 1:05:31 - loss: 846.7020 - ps - ETA: 1:04:36 - - ETA: 1:04:29 - loss: 846.4538 - psnr_me - ETA: 1:0 - ETA: 1:03:38 - loss: 846.2979 - psnr_metric - ETA: 1:03:37 - loss: 846.25 - ETA: 1:02:41 - loss: 846.0090 - psnr_metric: 22 - ETA: 1:02:20 - los - ETA: 1:02:14 - loss: 845.9739 - psnr_me - ETA: 1 - ETA: 1:01:53 - loss - ETA: 1:01:46 - loss: 845. - E - ETA: 1:01:32 - loss: 845.9419 - psnr_metric: 22.5 - ETA: 1:01:31 - loss: 845.9312 - p - ETA: 1:01:28 - loss: 845.8869 - p - ETA: 1:01:24 - loss: 845.8689 - psnr_metric: 22.583 - ETA: 1:01 - ETA: 59:35 - loss: 845.9339 - psnr_metric: 22.584 - ETA - ETA: 59:26 - loss: 845.8511 - psnr_metric: - ETA: 5 - ETA: 59:17 - loss: 845.8036 - p - ETA: 59:14 - loss: 845.7835 - ps - ETA: 59:11 - loss: 845.7740 - ps - ETA: 59:07 - loss: 845.7729 - psnr_ - ETA: 59:04 - loss - ETA: 58:58 - - ETA: 58:51 - loss: 845.6039 - psnr_metric: 22.5 - ETA: 57:23 - loss: 845.3842 - psnr_metric: 22. - ETA: 57:22 - loss: 845.3839 - psnr_met - ETA: 57:20 - loss: 845.4093 - psnr_metric - ETA: 57:18 - loss: 845. - ETA: 57:13 - loss: - ETA: 57:07 - loss: 845.4301 - psnr_metr - ETA: 55:48 - loss: 845.3300 - psnr_metric: 2 - ETA: 55:47 - loss: 845.3528 -  - ETA: 55:43 - loss: 845.3555 -  - ETA: 53:33 - - ETA: 53:26 - loss: 845.1208 - psnr_metri - ETA: 53:24 - loss - ETA: 53:08 - loss: 845 - ETA: 51:45 - loss: - - ETA: 50:31 - loss:  - ETA: 50:06 - loss: 845.6933 - psnr_metric: 22.58 - ETA: 50:06 - loss: 845.6948 - psnr_metric: 22 - ETA: 50:05 - l - ETA: 49:48 - loss: 845.6367 - psnr_metric: 22. - ETA: 49:48 - loss: 845.61 - ETA: 49 - ETA: 49:25 - loss: 845.6143 - psnr_metric: 22.587 - ETA: 49:25 - loss: 84 - ETA: 49:20 - loss: 845.5876 - p - ETA: 49:16 - loss: 845.5810 - psnr_metric: 22. - ETA: 49:16 - loss: 845.5801 - ETA: 49:11 - loss: 845.5380 - ps - ETA: 49:08 - loss: - ETA: 49:02 - loss: 845.4174 - ps - ETA: 48:59 - loss: 845.4531 - psnr_met - ETA: 48:57 - loss: 8 - E - ETA: 48:32 - loss: 845.3386 - psnr_metri - ETA: - ETA: 48:22 - loss: 845.2403 - psnr_m - ETA: 48:20 - loss: 845.2363  - ETA: 48:16 - loss: 845.2 - ETA: 48:11 - lo - ETA: 48:04 - loss - - ETA: 47:29 - loss: 845.2561 -  - ETA: 47:26 - loss: 845.2106 - psnr_metric: 22.588 - ETA: 47:26 - loss: 845.2 -  - ETA: 46:42 - loss: 845.3050 - psn - - ETA: 46:1 - ETA: 46:03 - loss: 8 - ETA: 45:01 - loss: 845.2030   - ETA: 44:47 - loss: 845 - ETA: 44:33 - loss: 845.2849 - psn - ETA: 44:30 - loss: 845.3115 - psnr_metric: 22 - ETA: 44:29 - loss: 845.3315 - psnr_metr - ETA: 44:27 - - ETA: 44:00 - loss: 845.2559 - psnr_metric: 22.588 - ETA: 44:00 - ETA: 43:43 - loss: 845.2280 - psnr_metric: 22.5 - ETA: 43:42 - loss: 845.2183 - psnr_metric: 22.5 - ETA: 43:42 - loss: 845.2104 - psnr_metric: - ETA: 43:40 - l - ETA: 38:40 - loss: 845.1595 - psnr_metric - ETA: 38:39 - loss: 845.1449 - psnr_met - ETA: 37:47 - loss: 845. - ETA: 37:42 - loss: 845.1971 - p - ETA: 37:39 - loss: 845.2000  - ETA: 37:35 - loss: 845 - ETA: 37:30 - loss: 845.1783 - psnr_ - ETA: 37:27 - loss: 845.1628 - psnr_metric:  - ETA - ETA: 37:17 - loss: 8 - ETA: 3 - ETA: 36:54 - loss: 845.1906 - psnr_m - ETA: 36:51 -  - ETA: 36:44 - loss: 845.2391 - psnr_metric: 2 - ETA: 36:43 - loss: 845.1976 - psnr_metric: 2 - ETA: 36:42 - loss: 845.1956 - psnr_metri - ETA: 36:40 - loss: 845.1971 - psnr_met - ETA: 36:38 - loss: 845.2079  - ETA: 36:34 - loss: 8 - ETA: 36:29 - loss: 845.1794 - psnr_metric: 22. - ETA: 36:28 - loss: 845.1879 - ps - ETA: 36:24 - loss: 845 - ETA: 36:19 - loss: 845.238 - ETA: 36:15 - loss: 845.2629 - psnr_metric: 22.58 - ET - ETA: 34:47 - loss: 845.2403 - ps - ETA: 34:44 -  - ETA: 34:37 - loss: 845.1833 - psnr_metric: 22.5 - ETA:  - ETA: 33:40 - lo - ETA: 33:33 - loss: 845.0751 - psnr_metr - E - ETA: 32:53 - loss: 845.1564 - ETA: 32:49 - loss: 845.1831 - psnr_metric:  - ETA: 32:47 - loss: 84 - E - ETA: 31:34 - loss: 845.3344 - psnr - ETA: 31:31 - loss: 845.3529 - psnr_metric: 22.587 - ETA: 31:31 - loss: 845.3540 - psnr_metric:  - ETA: 31:30 - loss: 845.3301 -  - ETA: 31:26 - loss: 84 - ETA: 31:21 - loss: 845.3167 - psnr_metric: 22.5 - ETA: 31:20 - loss: 845.3061  - ETA: 31:16 - loss: 845.3136 - psn - ETA: 31:13 - loss: - ETA: 30:28 - loss: 845.282 - ETA: 30:04 - loss: 84 - ETA: 26:54 - loss: 845.1103 - psnr_metric: - ETA: 26:53 - los - ETA: 24:49 - loss: 845.1996 - psnr_metric: 22.588 - ETA: 24:48 - loss: 845.1  - ETA: 24:24 - loss: 845.0895 - psnr_m - ETA: 24:22 - loss: 845.0961 - psnr_metric: 22.588 - ETA: 24:21 - loss: 845.0881 - psnr_metric: 22 - ETA: 24:20 - loss: 845.0988 - psnr_metric: 22.58 - ETA: 24:20 - loss: 845.0911 -  - ETA: 24:16 - loss: 8 - ETA: 24:11 - loss: 845.0856 - psnr_metric: 22 - ETA: 24:10 - loss: 845.1100 - psnr_metri - ETA: 24:08 - l - ETA:  - ETA: 23:53 - loss: 845.0305 - psnr_metric: 22.5 - ETA: 23:53 - loss: 845.0322 - psnr_metric: 22.5 - ETA: 23:52 - loss: 845.0192 - psnr_metr - ETA: 23:50 - loss: 845.0198 - psnr_me - ETA: 23:48 - loss: 845.0015 - psnr_metri - ETA: 23:46 - loss: 8 - ETA: 23:40 - los - ETA: 23:34 - loss: 844.9805 - psnr_metr - ETA: 23:22 - loss: 845.1263 - psnr_metric: 22.5 - ETA: 23:22 - loss: 845.1068 - psnr_metric: 22.588 - ETA: 23:21 - loss: 84 - ETA: 23:16 - l - ETA: 22:40 - loss: 845.1389 - psnr_metric - ETA: 22:39 - loss: 845.1453 - psnr - ETA: 22:36 - ETA: 21:59 - loss: 845.0414 - psnr_metric: 2 - ETA: 21:58 - loss:  - ETA: 21:52 - loss: 844.9899 - psnr_metr - ETA: 21:50 - loss: 844.979 - ETA: 21:46 - loss: 844.9526 - ET - ETA: 21:13 - loss:  - ETA: 21:07 - - ETA: 20:31 - loss: 844.836 - ETA: 19:47 - loss: 844.9186 - psnr_metric: 22. - ETA: 19:47 - loss: - ETA:  - ETA: 19:32 - loss: 844.9269 - psnr_metric: 22.589 - ETA: 19:32 - loss: 844.9254 - psnr_metric: 22.5 - ETA:  - ETA: 19:23 - loss: 844.9364 - psnr_metric: - ETA: 19:22 - loss: 844.9551  - ETA: 19:18 - loss: 844.9230 - psnr_metric:   - - ETA: 18:18 - loss: 844.8878 - psn - ETA: 18:15 - loss: 844.8845 - psnr - E - ETA: 18:03 - loss: 844.9321 - psnr_metric - ETA: 18:01 - loss: 844.9283 - psnr_metr - ETA: 17:59 - loss: 844.9834  - ETA: 17:46 - loss: 844.92 - ETA:  - E - ETA: 17:24 - loss: 844.9  - ETA: 16:59 - loss: 844.9279 - psn - ETA: 16:56 - loss: 844.9681 - psnr - ETA: 16:53 -  - ETA: 16:46 - lo - ETA: 16:40 - loss: 844.9997 - psnr_metr - ETA: 16:38 - loss: 845.0028 - psnr_metr - ETA: 16:26 - - ETA: 16:09 - loss: 844.9984 - psnr_metric: 22. - ETA: 16:09 - l - ETA: 16:02 - loss: 845.0055 -  - ETA: 15:49 - loss: 844.9722 - psn - ETA: 15:45 - loss: 844.9847 - psnr_metri - ETA - ETA: 15:35 - loss: 844.9222 - psnr - ETA: 15:32  - ETA: 14:46 - loss: 845. - ETA: 14:41 - l - ETA: 14:34 - loss: 845. - ETA: 14:29 - loss: 845.0596 - psnr_metri - ETA: 14:27 - loss: 845.119 - ETA: 14:13 - loss: 845. - ETA: 14:08 - loss: 845.0641 - psnr_metri - ETA: 14:06 - loss: 845.0814 - psnr_metric: 2 - ETA: 1 - ETA: 13:47 - loss: 845.0716 - p - ETA: 13:43 - loss: 845.0623 - psnr_metric: - ETA: 13:42 - loss: 845.1022 - psnr_metri - ETA: 13:40 -  - ETA: 13: - ETA: 13 - ETA: 12:48 - loss: 845.1907 - psnr_ - ETA - ETA: 10:49 - loss: 845.1340  - ETA: 10:35 - loss: 845.1618 - psnr_metri - ETA: 10:33 - loss: 845 - ETA: 10:18 - loss: 845.1477 - p - ETA: 10:15 - loss: 845.1178 - psnr_metric: 2 - ETA: 10:14 - loss: 845.1046 - psnr_metric: 22. - ETA: 10:13 - - ETA: 9:24 - loss: 845.1877 - psnr_metric: 22. - ETA: 9:23 - loss: 845.1856  - ETA: 9:21 - loss: 8 - ETA: 9:14 - loss: 845.1322 - psnr_metric: 22. - ETA: 9:13 - loss: 845.1335 - psnr_metric: 22.58 - ETA: 9:13 - loss: 845.1277 - psnr_metric: 22.58 - ETA: 9:13 - loss: 845.1251 - psnr_metric: - ETA: 9:12 - loss: 845.1155 - psnr_met - ETA: 2:51 - loss: 844.7427 - psnr_metric: 2 - ETA: 2:51 - - ETA: 44s -  - ETA: 37s - loss: 844.6871 - psnr_metri - ETA: 35s - loss: 84 - ETA: 1s - loss: 844.6907 - psnr_met"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[1,1356,2040,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf.nn.relu_37/Relu-0-0-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_2027379]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4b6d35acb9fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msave_checkpoint_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveCustomCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpsnr_metric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dataset_subset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremaining_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_checkpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training already completed. To continue training, increase the number of training steps\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1,1356,2040,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf.nn.relu_37/Relu-0-0-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_2027379]"
     ]
    }
   ],
   "source": [
    "training_steps = 1_000_000-14999-500-385519-53291-28745-14567-458046\n",
    "\n",
    "steps_per_epoch = 1_000_000-14999-500-385519-53291-28745-14567-458046\n",
    "\n",
    "training_epochs = training_steps / steps_per_epoch\n",
    "\n",
    "if checkpoint.epoch.numpy() < training_epochs:\n",
    "    remaining_epochs = int(training_epochs - checkpoint.epoch.numpy())\n",
    "    print(f\"Continuing Training from epoch {checkpoint.epoch.numpy()}. Remaining epochs: {remaining_epochs}.\")\n",
    "    save_checkpoint_callback = SaveCustomCheckpoint(checkpoint_manager, steps_per_epoch)\n",
    "    checkpoint.model.compile(optimizer=checkpoint.optimizer, loss=MeanSquaredError(), metrics=[psnr_metric])\n",
    "    checkpoint.model.fit(train_dataset,validation_data=valid_dataset_subset, steps_per_epoch=steps_per_epoch, epochs=remaining_epochs, callbacks=[save_checkpoint_callback])\n",
    "else:\n",
    "    print(\"Training already completed. To continue training, increase the number of training steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45d8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srresnet_{dataset_key}\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.tf'\n",
    "checkpoint.model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603dc7a",
   "metadata": {},
   "source": [
    "## Train SRGAN using SRResNet as the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_srresnet(scale=dataset_parameters.scale)\n",
    "generator.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator(hr_crop_size=hr_crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84efb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_5_4 = 20\n",
    "vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "perceptual_model = Model(vgg.input, vgg.layers[layer_5_4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9008cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy = BinaryCrossentropy()\n",
    "mean_squared_error = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba83996",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(learning_rate=learning_rate)\n",
    "discriminator_optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan_checkpoint_dir=f'./ckpt/srgan_{dataset_key}'\n",
    "\n",
    "srgan_checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                       psnr=tf.Variable(0.0),\n",
    "                                       generator_optimizer=Adam(learning_rate),\n",
    "                                       discriminator_optimizer=Adam(learning_rate),\n",
    "                                       generator=generator,\n",
    "                                       discriminator=discriminator)\n",
    "\n",
    "srgan_checkpoint_manager = tf.train.CheckpointManager(checkpoint=srgan_checkpoint,\n",
    "                                                directory=srgan_checkpoint_dir,\n",
    "                                                max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if srgan_checkpoint_manager.latest_checkpoint:\n",
    "    srgan_checkpoint.restore(srgan_checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {srgan_checkpoint.step.numpy()} with validation PSNR {srgan_checkpoint.psnr.numpy()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(lr, hr):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        lr = tf.cast(lr, tf.float32)\n",
    "        hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "        sr = srgan_checkpoint.generator(lr, training=True)\n",
    "\n",
    "        hr_output = srgan_checkpoint.discriminator(hr, training=True)\n",
    "        sr_output = srgan_checkpoint.discriminator(sr, training=True)\n",
    "\n",
    "        con_loss = calculate_content_loss(hr, sr)\n",
    "        gen_loss = calculate_generator_loss(sr_output)\n",
    "        perc_loss = con_loss + 0.001 * gen_loss\n",
    "        disc_loss = calculate_discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(perc_loss, srgan_checkpoint.generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, srgan_checkpoint.discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, srgan_checkpoint.generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, srgan_checkpoint.discriminator.trainable_variables))\n",
    "\n",
    "    return perc_loss, disc_loss\n",
    "\n",
    "@tf.function\n",
    "def calculate_content_loss(hr, sr):\n",
    "    sr = preprocess_input(sr)\n",
    "    hr = preprocess_input(hr)\n",
    "    sr_features = perceptual_model(sr) / 12.75\n",
    "    hr_features = perceptual_model(hr) / 12.75\n",
    "    return mean_squared_error(hr_features, sr_features)\n",
    "\n",
    "def calculate_generator_loss(sr_out):\n",
    "    return binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n",
    "\n",
    "def calculate_discriminator_loss(hr_out, sr_out):\n",
    "    hr_loss = binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n",
    "    sr_loss = binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n",
    "    return hr_loss + sr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c41e85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perceptual_loss_metric = Mean()\n",
    "discriminator_loss_metric = Mean()\n",
    "\n",
    "step = srgan_checkpoint.step.numpy()\n",
    "steps = 200000\n",
    "\n",
    "monitor_folder = f\"monitor_training/srgan_{dataset_key}\"\n",
    "os.makedirs(monitor_folder, exist_ok=True)\n",
    "\n",
    "now = time.perf_counter()\n",
    "\n",
    "for lr, hr in train_dataset.take(steps - step):\n",
    "    srgan_checkpoint.step.assign_add(1)\n",
    "    step = srgan_checkpoint.step.numpy()\n",
    "\n",
    "    perceptual_loss, discriminator_loss = train_step(lr, hr)\n",
    "    perceptual_loss_metric(perceptual_loss)\n",
    "    discriminator_loss_metric(discriminator_loss)\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        psnr_values = []\n",
    "        \n",
    "        for lr, hr in valid_dataset_subset:\n",
    "            sr = srgan_checkpoint.generator.predict(lr)[0]\n",
    "            sr = tf.clip_by_value(sr, 0, 255)\n",
    "            sr = tf.round(sr)\n",
    "            sr = tf.cast(sr, tf.uint8)\n",
    "            \n",
    "            psnr_value = psnr_metric(hr, sr)[0]\n",
    "            psnr_values.append(psnr_value)\n",
    "            psnr = tf.reduce_mean(psnr_values)\n",
    "            \n",
    "        image = Image.fromarray(sr.numpy())\n",
    "        image.save(f\"{monitor_folder}/{step}.png\" )\n",
    "        \n",
    "        duration = time.perf_counter() - now\n",
    "        \n",
    "        now = time.perf_counter()\n",
    "        \n",
    "        print(f'{step}/{steps}, psnr = {psnr}, perceptual loss = {perceptual_loss_metric.result():.4f}, discriminator loss = {discriminator_loss_metric.result():.4f} ({duration:.2f}s)')\n",
    "        \n",
    "        perceptual_loss_metric.reset_states()\n",
    "        discriminator_loss_metric.reset_states()\n",
    "        \n",
    "        srgan_checkpoint.psnr.assign(psnr)\n",
    "        srgan_checkpoint_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srgan_{dataset_key}\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "srgan_checkpoint.generator.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc9d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
